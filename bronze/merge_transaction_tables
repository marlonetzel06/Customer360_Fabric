-- load tables into PySpark Notebook
df_crm = spark.read.table("bronze_transactions_crm")
df_erp = spark.read.table("bronze_transactions_erp")
df_bi  = spark.read.table("bronze_transactions_bi")

-- Merge all 3 transaction tables

%%sql
CREATE OR REPLACE TABLE C_A_360_LH.bronze_transactions_all AS

SELECT
    Transaktion_ID,
    Kunden_ID,
    Service,
    CAST(`Betrag_€` AS DOUBLE) AS Betrag_EUR,
    Datum,
    Status,
    SPLIT(Transaktion_ID, '_')[0] AS Quellsystem
FROM 
    bronze_transactions_bi

UNION ALL 

SELECT
    Transaktion_ID,
    Kunden_ID,
    Service,
    CAST(`Betrag_€` AS DOUBLE) AS Betrag_EUR,
    Datum,
    Status,
    SPLIT(Transaktion_ID, '_')[0] AS Quellsystem
FROM
    bronze_transactions_crm

UNION ALL 

SELECT
  Transaktion_ID,
  Kunden_ID,
  Service,
  CAST(`Betrag_€` AS DOUBLE) AS Betrag_EUR,
  Datum,
  Status,
  SPLIT(Transaktion_ID, '_')[0] AS Quellsystem
FROM 
    bronze_transactions_erp;
